---
title: "241121_PARAFAC_NMBU"
output:
  pdf_document: default
  html_document: default
date: "2024-11-21"
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Here follows an analysis of fluorescence EEM data from NMBU. 
The data was produced from analysing GF filtered water samples from a lake, covering:
- 60 samples from the top
- 60 samples from the bottom
 
Follow this procedure: https://cran.r-project.org/web/packages/staRdom/vignettes/PARAFAC_analysis_of_EEM.html#raman-normalisation

QUESTIONS to NMBU
* negative abs-values, likely to influence?
- instrumental correction? likely not necessary
- there might be some signal in the blanks - influential?
- no dilutions performed?
- ok to cut the area with the lowest ex wavelengths?

# Preparations
Load required packages
```{r Loading required packages required packages, message=FALSE, warning=FALSE}
Packages <- c("staRdom", "dplyr", "tidyr", "data.table", "reshape")
#"libwgeom",
lapply(Packages, library, character.only = TRUE)
cores <- detectCores(logical = FALSE)
```

Set directories and load data, and check that the lengts are similar
```{r set data directory and read fluorescence data, fig.cap= "Uncorrected EEMs"}
folder = "C:/Users/CBG/OneDrive - NIVA/1 Projects/NMBU_PARAFAC/PARAFAC_filer"
eem_list <- eem_read(folder, import_function = "cary", recursive = TRUE)
eem_overview_plot(eem_list[1:9], spp=9, contour = TRUE)

#Absorbance data
absorbance_dir="C:/Users/CBG/OneDrive - NIVA/1 Projects/NMBU_PARAFAC/Abs_GF_Data_parafac.csv" 
absy <- absorbance_read(absorbance_dir, order=TRUE)

metatable = "C:/Users/CBG/OneDrive - NIVA/1 Projects/NMBU_PARAFAC/241121_NMBU_PARAFAC_Metadata.txt"
meta <- read.table(metatable, header = TRUE, sep = "\t", dec = ".", row.names=1)

length(eem_list)
ncol(absy)
nrow(meta)
```

# 1) Absorbance wavenegth correction
```{r absorbance wavenength correction}
absorbance <- abs_blcor(absy,wlrange = c(680,700))
```

## Check the data for inconsistencies 
- seems ok (output from test not plotted here)
```{r Check the data for inconsistencies, message = FALSE}
#summary(eem_list)
nrow(meta)
#problem <- eem_checkdata(eem_list,absorbance, metadata=meta)
```

# 2) Spectral correction with instrument file (not done)
- is this necessary for the instrument at NMBU?
- at NIVA we used, for excorr, measurements from a rhodamineB standard solution at 550nm while nothing for the emcorr 

```{r Spectral corrections, include = FALSE}
#excorfile= "C:/Users/CBG/OneDrive - NIVA/1 Projects/1000 Lakes fEEM Data/DOM-1000-lake-PARAFAC/Data/RhodamineB_ex #correction.txt"
#Excorr <- data.table::fread(excorfile)
#emcorfile = "C:/Users/CBG/OneDrive - NIVA/1 Projects/1000 Lakes fEEM Data/DOM-1000-lake-PARAFAC/Data/Ex #correction_fake.txt"
#Emcorr <- data.table::fread(emcorfile)
#eem_listc <- eem_spectral_cor(eem_list,Excorr, Emcorr)
#eem_overview_plot(eem_list, spp=9, contour = TRUE)
```

# 3) Blank subtraction. 
```{r Blank correction, message = FALSE, fig.cap="EEMs blank corrected"}
eemss <- eem_remove_blank(eem_list)
length(eemss)
eem_overview_plot(eemss[1:9], spp=9, contour = TRUE)
```

# 4) Inner filter effect correction using absorption data 
- all abs data must be below 2.0 at any wavelength (else, dilution). 
- Several values from the absorbancy data are negative. Will this cause problems??? 
```{r Correct for IFE, message = FALSE, warning=FALSE, fig.cap="EEMs corrected for blanks and inner filter effects"}
eemsss <- eem_ife_correction(eemss,absorbance, cuvl = 1)
eem_overview_plot(eemsss[1:9], spp=9, contour = TRUE)
```

# 5) Raman normalization
- could the negative abosrbance data cause problems here?
```{r Raman normalisation, message = FALSE, warning=FALSE, fig.cap="EEMs corrected for blanks and inner filter effects, and Raman normalised"}
eemsssy <- eem_raman_normalisation2(eemsss, blank = "blank")
eem_overview_plot(eemsssy[1:9], spp=9, contour = TRUE)

# ALTENRATIVE Raman normalization
# because of negative values. Will try alternative-manual way
#raman1 = "C:/Users/CBG/OneDrive - NIVA/1 Projects/1000 Lakes fEEM Data/DOM-1000-lake-PARAFAC/201216_RamanManual3.txt"
#raman2 <- read.table(raman1, header = TRUE, sep = "\t", dec = ".", row.names=1) # load data
#eemsss2 <- eem_raman_normalisation2(eemsss, blank = raman2)
```
#6) Remove blanks from sample set
```{r}
eemb <- eem_extract(eemsssy, c("nano", "miliq", "milliq", "mq", "blank", "Blank"),ignore_case = TRUE)
absorbance <- dplyr::select(absorbance, -matches("nano|miliq|milliq|mq|blank|Blank", ignore.case = TRUE))
```
# 7) Remove and interpolate scattering
- seems ok with regards to the Raman and Rayleigh
```{r Remove and interpolate scattering, fig.cap="EEMs corrected for blanks and inner filter effects, Raman normalised and scattering removed and interpolated"}
eem_overview_plot(eemb[1:9], spp=9, contour = TRUE)
remove_scatter <- c(TRUE, TRUE, TRUE, TRUE)
remove_scatter_width <- c(15,15,15,15) #is either a number or a vector of wavelength width in nm. “raman1”, “raman2”, “rayleigh1” and “rayleigh2”
eemsc <- eem_rem_scat(eemb, remove_scatter = remove_scatter, remove_scatter_width = remove_scatter_width)

#interpolate the removed datapoints
#different methods are available for interpretting .recommends to start with no 1
eemint <- eem_interp(eemsc, type = 1, extend = FALSE)
eem_overview_plot(eemint, spp=9, contour = TRUE)
```

# 8) Taking a look at the blanks
- since the blanks are used both for subtraction and making Raman area, it is worth looking into. 
- There is a signal at the shorter ex wavelengths and em 300-400 nm
```{r looking at blanks, message = FALSE, fig.cap="EEMs of the blanks with scattering removed and interpolated"}
#looking at the blanks
#Finding LOQ
blanks <- eem_extract(eem_list, c("nano", "miliq", "milliq", "mq", "blank", "Blank"),keep = TRUE)
blanks2 <- eem_rem_scat(blanks, remove_scatter = remove_scatter, remove_scatter_width = remove_scatter_width)
blanks3<- eem_interp(blanks2, type = 1, extend = FALSE)
blanks4 <- blanks3 %>% 
  eem_range(ex = c(250,Inf), em = c(0,580))

eem_overview_plot(blanks4, spp=9, contour = TRUE)

#could be considered if LOQ is needed
#bix <- eem_biological_index(blanks)
#coble_peaks <- eem_coble_peaks(blanks)
#fi <- eem_fluorescence_index(blanks)
#hix <- eem_humification_index(blanks, scale = TRUE)

#indices_peaks <- bix %>%
#  full_join(coble_peaks, by = "sample") %>%
#  full_join(fi, by = "sample") %>%
#  full_join(hix, by = "sample")

#indices_peaks

#barplot(indices_peaks$a)

#LOQ <- 10*sd(indices_peaks$a[1:10])
#LOQ
```

# 9) print a summary table of the samples 
- wavelength ranges, and corrections that have been done
```{r Summary}
summary(eemint)
```

# 10) Remove noisy area at low wavelength excitation 
```{r Remove noisy area, fig.cap="EEMS corrected and noisy area removed"}
eemint4 <- eemint %>% eem_range(ex = c(250,Inf), em = c(300,580))
#eem_overview_plot(eemint4, spp=9, contour = TRUE)
```

# 11) Peak picking
- smoothing can be performed prior to peak picking (not donw here)
  - from a quick look at BIX there are no big differences between the smoothed and the non-smoothed

```{r peak picking, message = FALSE, warning=FALSE}
#WITHOUT SMOOTHING
bix <- eem_biological_index(eemint4)
coble_peaks <- eem_coble_peaks(eemint4)
fi <- eem_fluorescence_index(eemint4)
hix <- eem_humification_index(eemint4, scale = TRUE)

indices_peaks <- bix %>%
  full_join(coble_peaks, by = "sample") %>%
  full_join(fi, by = "sample") %>%
  full_join(hix, by = "sample")

#combine with data and depth column from metadata
met <- data.table::fread("C:/Users/CBG/OneDrive - NIVA/1 Projects/NMBU_PARAFAC/241121_NMBU_PARAFAC_Metadata.txt", sep = "\t")

#merging with date from other dataset
df_merge <- merge(indices_peaks, met, by = "sample", 
                  all.x = TRUE) 

write.csv(df_merge,"C:/Users/CBG/OneDrive - NIVA/1 Projects/NMBU_PARAFAC/Output/NMBU_indices and peaks_NOsmooth.csv", row.names = FALSE)
```

```{r plot Coble indices, fig.cap="BIX"}
df_merge$date_analysis<-as.Date(df_merge$date_analysis,format="%d.%m.%Y")

class(df_merge$date_analysis)
ggplot(df_merge, aes(x=date_analysis, y=bix, fill=lake_layer))+
  geom_col(position = position_dodge2(width = 0.4, reverse=TRUE))+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  coord_cartesian(ylim = c(0.3, 0.7))
  

```

